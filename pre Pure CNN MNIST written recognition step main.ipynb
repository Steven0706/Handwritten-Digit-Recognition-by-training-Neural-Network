{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST hand written data reconition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat\n",
    "from math import sqrt\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can learn that \n",
    "1. use np.empty(0, X) to create a numpy style placeholder\n",
    "2. then use append to add data\n",
    "3. create the random permutation labels for randomnize the data\n",
    "4. the data is still 0 ~ 9 but the train and validation set are random permutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat('mnist_all.mat')\n",
    "# Dividing the data into training, test and Validation data\n",
    "data_train=np.empty((0,784))\n",
    "trn_lab=np.empty((0,1))\n",
    "data_test=np.empty((0,784))\n",
    "tes_lab=np.empty((0,1))\n",
    "data_val=np.empty((0,784))\n",
    "val_lab=np.empty((0,1))\n",
    "for i in range(10):\n",
    "    m1 = mat.get('test'+str(i))\n",
    "    m2 = mat.get('train'+str(i))\n",
    "    num1 = m1.shape[0]\n",
    "    num2 = m2.shape[0]\n",
    "    num3 = int(0.83342*num2)\n",
    "    num4 = num2 - num3\n",
    "    b = range(m2.shape[0])\n",
    "    permut_b = np.random.permutation(b)\n",
    "    Z1 = m2[permut_b[0:num3],:]\n",
    "    Z2 = m2[permut_b[num3:],:]\n",
    "    data_train = np.vstack([data_train,Z1])\n",
    "    data_val = np.vstack([data_val,Z2])\n",
    "    data_test = np.vstack([data_test,m1])\n",
    "    for p in range(num3):\n",
    "        trn_lab = np.append(trn_lab,i)\n",
    "    for q in range(num4):\n",
    "        val_lab = np.append(val_lab,i)\n",
    "    for r in range(num1):\n",
    "        tes_lab = np.append(tes_lab,i)\n",
    "    # normalizing the data to values between to 0-1.\n",
    "    data_test = data_test /255\n",
    "    data_train = data_train / 255\n",
    "    data_val = data_val / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'train0', 'test0', 'train1', 'test1', 'train2', 'test2', 'train3', 'test3', 'train4', 'test4', 'train5', 'test5', 'train6', 'test6', 'train7', 'test7', 'train8', 'test8', 'train9', 'test9'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5923, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['train0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111eb5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temppic = mat['train5'][100].reshape(28,28)\n",
    "plt.imshow(temppic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1118d24a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkIDX = 33420\n",
    "print (int(trn_lab[checkIDX]))\n",
    "plt.imshow(data_train[checkIDX].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print (data_train.shape)\n",
    "print (data_val.shape)\n",
    "print (data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#All check here\n",
    "train_data = data_train\n",
    "train_label = trn_lab\n",
    "validation_data = data_val\n",
    "validation_label = val_lab\n",
    "test_data = data_test\n",
    "test_label = tes_lab\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_label.shape) \n",
    "\n",
    "print(validation_data.shape)\n",
    "print(validation_label.shape)\n",
    "\n",
    "print(test_data.shape) \n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the CNN now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 layers in total: input, hidden, output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in input unit (not including bias unit)\n",
    "n_input = train_data.shape[1]; \n",
    "\n",
    "# set the number of nodes in hidden unit (not including bias unit)\n",
    "n_hidden = 50;\n",
    "\t\t\t\t   \n",
    "# set the number of nodes in output unit\n",
    "n_class = 10;\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight initialization\n",
    "Why we need the epsilon????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the weights into some random matrices\n",
    "#W: matrix of random initial weights with size (n_out x (n_in + 1))\"\"\"\n",
    "def initializeWeights(n_in,n_out):\n",
    "    \"\"\"\n",
    "    # initializeWeights return the random weights for Neural Network given the\n",
    "    # number of node in the input layer and output layer\n",
    "\n",
    "    # Input:\n",
    "    # n_in: number of nodes of the input layer\n",
    "    # n_out: number of nodes of the output layer\n",
    "       \n",
    "    # Output: \n",
    "    # W: matrix of random initial weights with size (n_out x (n_in + 1))\"\"\"\n",
    "    \n",
    "    #epsilon = sqrt(6) / sqrt(n_in + n_out + 1);\n",
    "    #W = (np.random.rand(n_out, n_in + 1)*2* epsilon) - epsilon;\n",
    "    # Why we need thing above?\n",
    "    W = np.random.rand(n_out, n_in + 1)\n",
    "    return W\n",
    "\n",
    "initial_w1 = initializeWeights(n_input, n_hidden);\n",
    "initial_w2 = initializeWeights(n_hidden, n_class);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get ready to use the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 785)\n",
      "(10, 51)\n"
     ]
    }
   ],
   "source": [
    "print (initial_w1.shape)\n",
    "print (initial_w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = initial_w1\n",
    "w2 = initial_w2\n",
    "obj_val = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To minimize the cost, we need proper define the cost function and its forms as \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "\n",
    "The objective function to be minimized. Must be in the form f(x, *args). The optimizing argument, x, is a 1-D array of points, and args is a tuple of any additional fixed parameters needed to completely specify the function.\n",
    "args : tuple, optional\n",
    "Extra arguments passed to the objective function and its derivatives (Jacobian, Hessian).\n",
    "\n",
    "Jacobian (gradient) of objective function. Only for CG, BFGS, Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov, trust-region-exact. If jac is a Boolean and is True, fun is assumed to return the gradient along with the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = np.array(train_label)\n",
    "rows = training_label.shape[0];\n",
    "rowsIndex=np.arange(rows,dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 49997, 49998, 49999])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowsIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  9.  9.  9.]\n"
     ]
    }
   ],
   "source": [
    "tempLabel = np.zeros((rows,10))\n",
    "tempLabel[rowsIndex,training_label.astype(int)]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_label = tempLabel  #one hot key result of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.column_stack((train_data,np.ones(train_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 785)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print (training_data.shape)\n",
    "number_of_samples = training_data.shape[0]\n",
    "print (number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let it propagate and calculate the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    \"\"\"# Notice that z can be a scalar, a vector or a matrix\n",
    "    # return the sigmoid of input z\"\"\"\n",
    "    sigmoid_result = 1.0 / (1.0 + np.exp(-1.0 * z));\n",
    "    return  sigmoid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 50)\n",
      "(50000, 51)\n"
     ]
    }
   ],
   "source": [
    "# passing the input data to the Hidden layer\n",
    "zj = sigmoid(np.dot(training_data,w1.T))\n",
    "print (zj.shape)\n",
    "# adding bias to the hidden layer\n",
    "zj = np.column_stack((zj,np.ones(zj.shape[0])))\n",
    "print (zj.shape)\n",
    "# passing the hidden layer data to the output layer\n",
    "ol = sigmoid(np.dot(zj,w2.T))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back propogation\n",
    "deltaOutput = ol - training_label\n",
    "error = np.sum(-1*(training_label*np.log(ol)+(1-training_label)*np.log(1-ol)))\n",
    "error = error/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the gradient and backprapagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaOutput = ol - training_label\n",
    "error = np.sum(-1*(training_label*np.log(ol)+(1-training_label)*np.log(1-ol)))\n",
    "error = error/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above function is the cost function of logistic regression\n",
    "https://www.coursera.org/learn/machine-learning/supplement/afqGa/cost-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_of_w2 = np.dot(deltaOutput.T,zj)\n",
    "gradient_of_w2 = gradient_of_w2/number_of_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The gradient of w2 is the delta times the zj (hidden layer values)\n",
    "key elements here:\n",
    "https://www.coursera.org/learn/machine-learning/supplement/pjdBA/backpropagation-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_of_w1 = np.dot(((1-zj)*zj* (np.dot(deltaOutput,w2))).T,training_data)\n",
    "gradient_of_w1 = gradient_of_w1/number_of_samples\t\n",
    "gradient_of_w1 = np.delete(gradient_of_w1, n_hidden,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [-0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [-0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -0.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -0.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -0.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(deltaOutput,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.99999984,  0.99999998,  0.99999991,  0.99999996,  0.99999982,\n",
       "        0.99999992,  0.99999965,  0.9999999 ,  0.99999998,  0.99999992])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ol[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0000009999998634"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.001**3 - (1-0.001)**3)/0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
